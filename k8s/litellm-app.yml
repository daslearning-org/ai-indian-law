apiVersion: v1
kind: Namespace
metadata:
  name: litellm

---

apiVersion: apps/v1
kind: Deployment
metadata:
  name: litellm
  namespace: litellm
spec:
  replicas: 1 # You can adjust the number of replicas as needed
  selector:
    matchLabels:
      app: litellm
  template:
    metadata:
      labels:
        app: litellm
    spec:
      #nodeSelector:
      #  cloud.google.com/gke-spot: "true" # Target Spot VMs
      containers:
        - name: ollama
          image: sdas92/law-litellm:v1 # Use the desired image
          ports:
            - containerPort: 4000 # The default port Open Web UI listens on
          env:
            - name: OLLAMA_API_BASE
              value: "http://ollama-service.ollama.svc.cluster.local"
          resources:
            requests:
              memory: "0.5Gi"
              cpu: "0.25"
              #ephemeral-storage: 4Gi
            limits:
              memory: "4Gi"
              cpu: "1"
              #ephemeral-storage: 16Gi
      #tolerations:
      #- key: "cloud.google.com/gke-spot"
      #  operator: "Equal"
      #  value: "true"
      #  effect: "NoSchedule"


---

apiVersion: v1
kind: Service
metadata:
  name: litellm-service
  namespace: litellm # Replace with your namespace
spec:
  type: ClusterIP # LoadBalancer Or ClusterIP for internal access, or Ingress
  selector:
    app: litellm
  ports:
  - protocol: TCP
    port: 80 # Port the service will listen on
    targetPort: 4000 # Port LiteLLM container is listening on
